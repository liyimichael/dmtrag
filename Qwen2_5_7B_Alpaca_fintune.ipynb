{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c19c23",
   "metadata": {},
   "source": [
    "# 1. å®‰è£…ä¾èµ–åº“\n",
    "ä½¿ç”¨pipå®‰è£…UnslothåŠç›¸å…³ä¾èµ–ï¼Œç¡®ä¿ç¯å¢ƒå‡†å¤‡å¥½ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…UnslothåŠç›¸å…³ä¾èµ–åº“ï¼Œå»ºè®®åœ¨å‘½ä»¤è¡Œæˆ–notebookä¸­è¿è¡Œ\n",
    "!pip install unsloth bitsandbytes accelerate xformers==0.0.29.post3 peft trl sentencepiece protobuf datasets huggingface_hub hf_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00529e58",
   "metadata": {},
   "source": [
    "# 2. åŠ è½½å’Œé…ç½®æ¨¡å‹\n",
    "å¯¼å…¥FastLanguageModelï¼Œè®¾ç½®æœ€å¤§åºåˆ—é•¿åº¦ã€æ•°æ®ç±»å‹å’Œæ˜¯å¦ä½¿ç”¨4bité‡åŒ–ï¼ŒåŠ è½½Qwen2.5-7Bé¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9abc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaoke/miniconda3/envs/unsloth/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.7.11: Fast Qwen2 patching. Transformers: 4.54.1.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 44.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥FastLanguageModelå’Œtorch\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048  # æœ€å¤§åºåˆ—é•¿åº¦ï¼Œå¯æ ¹æ®æ˜¾å­˜è°ƒæ•´\n",
    "dtype = None  # è‡ªåŠ¨æ£€æµ‹æ•°æ®ç±»å‹ï¼Œæ¨èfloat16æˆ–bfloat16\n",
    "load_in_4bit = True  # æ˜¯å¦ä½¿ç”¨4bité‡åŒ–ï¼ŒèŠ‚çœæ˜¾å­˜\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-7B\",  # é€‰æ‹©Qwen2.5-7Bæ¨¡å‹\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # å¦‚éœ€è®¿é—®å—é™æ¨¡å‹è¯·å¡«å†™token\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7552ad",
   "metadata": {},
   "source": [
    "# 3. æ·»åŠ LoRAé€‚é…å™¨\n",
    "ä¸ºæ¨¡å‹æ·»åŠ LoRAé€‚é…å™¨ï¼Œåªå¾®è°ƒéƒ¨åˆ†å‚æ•°ä»¥èŠ‚çœæ˜¾å­˜å’ŒåŠ é€Ÿè®­ç»ƒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1a98f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.7.11 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# ä¸ºæ¨¡å‹æ·»åŠ LoRAé€‚é…å™¨ï¼Œåªå¾®è°ƒéƒ¨åˆ†å‚æ•°ï¼ŒèŠ‚çœæ˜¾å­˜\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,  # LoRAç§©ï¼Œè¶Šå¤§å¯å¾®è°ƒå‚æ•°è¶Šå¤š\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,  # æ¨èä¸º0ï¼Œä¼˜åŒ–æ˜¾å­˜\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",  # æ”¯æŒé•¿ä¸Šä¸‹æ–‡\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1be69c",
   "metadata": {},
   "source": [
    "# 4. å‡†å¤‡Alpacaæ•°æ®é›†\n",
    "åŠ è½½Alpacaä¸­æ–‡æ•°æ®é›†ï¼Œä¹Ÿå¯æ›¿æ¢ä¸ºè‡ªå®šä¹‰æ•°æ®é›†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b624e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½Alpacaæ•°æ®é›†ï¼Œå¯æ›¿æ¢ä¸ºè‡ªå®šä¹‰æ•°æ®é›†\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\")  # é»˜è®¤åŠ è½½è‹±æ–‡ï¼Œå¯æ›¿æ¢ä¸ºä¸­æ–‡æˆ–è‡ªå®šä¹‰æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7100a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 51760\n",
      "})\n",
      "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.', 'text': 'ä»¥ä¸‹æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œé…æœ‰è¿›ä¸€æ­¥çš„è¾“å…¥ä¿¡æ¯ã€‚è¯·æ ¹æ®è¦æ±‚å®Œæˆå›å¤ã€‚\\n\\n### æŒ‡ä»¤:\\nGive three tips for staying healthy.\\n\\n### è¾“å…¥:\\n\\n\\n### å›å¤:\\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|endoftext|>'}\n"
     ]
    }
   ],
   "source": [
    "# æ‰“å°æ•°æ®é›†çœ‹çœ‹\n",
    "print(dataset)\n",
    "print(dataset[0])  # æ‰“å°ç¬¬ä¸€æ¡æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7cdec9",
   "metadata": {},
   "source": [
    "# 5. æ ¼å¼åŒ–æ•°æ®å¹¶æ·»åŠ EOSæ ‡è®°\n",
    "å®šä¹‰æ ¼å¼åŒ–å‡½æ•°ï¼Œå°†æŒ‡ä»¤ã€è¾“å…¥å’Œè¾“å‡ºæ‹¼æ¥ä¸ºè®­ç»ƒæ–‡æœ¬ï¼Œå¹¶åœ¨æœ«å°¾æ·»åŠ EOSæ ‡è®°ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5cc8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51760/51760 [00:00<00:00, 89056.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰æ ¼å¼åŒ–å‡½æ•°ï¼Œå°†æŒ‡ä»¤ã€è¾“å…¥ã€è¾“å‡ºæ‹¼æ¥ä¸ºè®­ç»ƒæ–‡æœ¬ï¼Œå¹¶æ·»åŠ EOSæ ‡è®°\n",
    "alpaca_prompt = \"\"\"ä»¥ä¸‹æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œé…æœ‰è¿›ä¸€æ­¥çš„è¾“å…¥ä¿¡æ¯ã€‚è¯·æ ¹æ®è¦æ±‚å®Œæˆå›å¤ã€‚\\n\\n### æŒ‡ä»¤:\\n{}\\n\\n### è¾“å…¥:\\n{}\\n\\n### å›å¤:\\n{}\"\"\"\n",
    "EOS_TOKEN = tokenizer.eos_token  # è·å–æ¨¡å‹çš„EOSæ ‡è®°\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # æ‹¼æ¥æŒ‡ä»¤ã€è¾“å…¥å’Œè¾“å‡ºï¼Œå¹¶æ·»åŠ EOSæ ‡è®°\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd8f035",
   "metadata": {},
   "source": [
    "# 6. è®­ç»ƒæ¨¡å‹\n",
    "ä½¿ç”¨TRLçš„SFTTrainerè¿›è¡Œå¾®è°ƒï¼Œè®¾ç½®è®­ç»ƒå‚æ•°å¦‚æ‰¹æ¬¡å¤§å°ã€å­¦ä¹ ç‡ã€è®­ç»ƒæ­¥æ•°ç­‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e98fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51760/51760 [00:15<00:00, 3264.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨SFTTrainerè¿›è¡Œå¾®è°ƒï¼Œè®¾ç½®è®­ç»ƒå‚æ•°\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    packing = False,  # çŸ­åºåˆ—å¯åŠ é€Ÿè®­ç»ƒ\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 60,  # è®­ç»ƒæ­¥æ•°ï¼Œå¯æ ¹æ®éœ€æ±‚è°ƒæ•´\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"model_train_outputs\",\n",
    "        report_to = \"none\",  # å¯æ¥å…¥WandBç­‰å·¥å…·\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702363df",
   "metadata": {},
   "source": [
    "# 7. æ˜¾ç¤ºæ˜¾å­˜ä¿¡æ¯\n",
    "é€šè¿‡torch.cudaè·å–å’Œæ‰“å°æ˜¾å¡æ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼Œä¾¿äºç›‘æ§èµ„æºæ¶ˆè€—ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4df204b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUå‹å·: NVIDIA RTX A6000ï¼Œæœ€å¤§æ˜¾å­˜: 44.988 GB\n",
      "å·²é¢„ç•™æ˜¾å­˜: 7.246 GB\n"
     ]
    }
   ],
   "source": [
    "# æ˜¾ç¤ºå½“å‰GPUæ˜¾å­˜ä¿¡æ¯ï¼Œä¾¿äºç›‘æ§èµ„æºæ¶ˆè€—\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPUå‹å·: {gpu_stats.name}ï¼Œæœ€å¤§æ˜¾å­˜: {max_memory} GB\")\n",
    "print(f\"å·²é¢„ç•™æ˜¾å­˜: {start_gpu_memory} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c8a8357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 51,760 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 40,370,176 of 7,655,986,688 (0.53% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 02:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.775800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.696800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.580400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.965500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.191100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.986400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.791500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.884500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.774800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.913900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.927200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.756200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.833500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.926800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.905400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.995100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.967200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.984600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.861700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.718300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.819800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.942400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.797400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.785200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.764900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.668200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.843900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.907300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.850500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.888500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.734200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.822300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.980300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.857500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.950300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.729500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.816300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.708700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.755700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.826000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒè€—æ—¶: 180.6005 ç§’\n",
      "è®­ç»ƒè€—æ—¶: 3.01 åˆ†é’Ÿ\n",
      "è®­ç»ƒæœŸé—´å³°å€¼æ˜¾å­˜: 8.635 GBï¼Œå æœ€å¤§æ˜¾å­˜ 19.194%\n",
      "LoRAè®­ç»ƒæ˜¾å­˜: 1.389 GBï¼Œå æœ€å¤§æ˜¾å­˜ 3.087%\n"
     ]
    }
   ],
   "source": [
    "# å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œå¹¶æ˜¾ç¤ºè®­ç»ƒç»“æœå’Œæ˜¾å­˜å˜åŒ–\n",
    "trainer_stats = trainer.train()\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"è®­ç»ƒè€—æ—¶: {trainer_stats.metrics['train_runtime']} ç§’\")\n",
    "print(f\"è®­ç»ƒè€—æ—¶: {round(trainer_stats.metrics['train_runtime']/60, 2)} åˆ†é’Ÿ\")\n",
    "print(f\"è®­ç»ƒæœŸé—´å³°å€¼æ˜¾å­˜: {used_memory} GBï¼Œå æœ€å¤§æ˜¾å­˜ {used_percentage}%\")\n",
    "print(f\"LoRAè®­ç»ƒæ˜¾å­˜: {used_memory_for_lora} GBï¼Œå æœ€å¤§æ˜¾å­˜ {lora_percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494c7e6",
   "metadata": {},
   "source": [
    "# 8. æ¨¡å‹æ¨ç†ï¼ˆç”Ÿæˆæ–‡æœ¬ï¼‰\n",
    "å¯ç”¨æ¨ç†æ¨¡å¼ï¼Œè¾“å…¥æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆæ¨¡å‹è¾“å‡ºï¼Œå¹¶å±•ç¤ºå¦‚ä½•ä½¿ç”¨TextStreameræµå¼è¾“å‡ºç»“æœã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ecec938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ä»¥ä¸‹æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œé…æœ‰è¿›ä¸€æ­¥çš„è¾“å…¥ä¿¡æ¯ã€‚è¯·æ ¹æ®è¦æ±‚å®Œæˆå›å¤ã€‚\\n\\n### æŒ‡ä»¤:\\nè¯·ç»­å†™æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚\\n\\n### è¾“å…¥:\\n1, 1, 2, 3, 5, 8\\n\\n### å›å¤:\\n13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6']\n",
      "ä»¥ä¸‹æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œé…æœ‰è¿›ä¸€æ­¥çš„è¾“å…¥ä¿¡æ¯ã€‚è¯·æ ¹æ®è¦æ±‚å®Œæˆå›å¤ã€‚\n",
      "\n",
      "### æŒ‡ä»¤:\n",
      "è¯·ç»­å†™æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚\n",
      "\n",
      "### è¾“å…¥:\n",
      "1, 1, 2, 3, 5, 8\n",
      "\n",
      "### å›å¤:\n",
      "13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75077, 121393, 193491, 194676, \n"
     ]
    }
   ],
   "source": [
    "# å¯ç”¨æ¨ç†æ¨¡å¼ï¼Œè¾“å…¥æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆæ¨¡å‹è¾“å‡º\n",
    "FastLanguageModel.for_inference(model)  # å¼€å¯é«˜æ•ˆæ¨ç†æ¨¡å¼\n",
    "inputs = tokenizer([\n",
    "    alpaca_prompt.format(\n",
    "        \"è¯·ç»­å†™æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚\",  # æŒ‡ä»¤\n",
    "        \"1, 1, 2, 3, 5, 8\",  # è¾“å…¥\n",
    "        \"\",  # è¾“å‡ºç•™ç©ºï¼Œæ¨¡å‹è‡ªåŠ¨ç”Ÿæˆ\n",
    "    )\n",
    "], return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
    "print(tokenizer.batch_decode(outputs))  # è¾“å‡ºç”Ÿæˆç»“æœ\n",
    "\n",
    "# ä½¿ç”¨TextStreameræµå¼è¾“å‡ºç»“æœ\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4211a10",
   "metadata": {},
   "source": [
    "# 9. ä¿å­˜å’ŒåŠ è½½å¾®è°ƒåçš„æ¨¡å‹\n",
    "ä¿å­˜LoRAé€‚é…å™¨å’Œåˆ†è¯å™¨åˆ°æœ¬åœ°æˆ–ä¸Šä¼ åˆ°Hugging Face Hubï¼Œå¹¶æ¼”ç¤ºå¦‚ä½•é‡æ–°åŠ è½½ç”¨äºæ¨ç†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜LoRAé€‚é…å™¨å’Œåˆ†è¯å™¨åˆ°æœ¬åœ°\n",
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")\n",
    "# ä¸Šä¼ åˆ°Hugging Face Hubï¼ˆéœ€å¡«å†™tokenï¼‰\n",
    "# model.push_to_hub(\"ä½ çš„ç”¨æˆ·å/lora_model\", token=\"ä½ çš„token\")\n",
    "# tokenizer.push_to_hub(\"ä½ çš„ç”¨æˆ·å/lora_model\", token=\"ä½ çš„token\")\n",
    "\n",
    "# é‡æ–°åŠ è½½å¾®è°ƒåçš„æ¨¡å‹ç”¨äºæ¨ç†\n",
    "if False:\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"lora_model\",\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2497ef6",
   "metadata": {},
   "source": [
    "# 10. ä¿å­˜ä¸ºfloat16æˆ–GGUFæ ¼å¼\n",
    "å±•ç¤ºå¦‚ä½•å°†æ¨¡å‹ä¿å­˜ä¸ºfloat16æˆ–GGUFæ ¼å¼ï¼Œæ”¯æŒVLLMå’Œllama.cppç­‰æ¨ç†æ¡†æ¶ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8185a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜ä¸ºfloat16æ ¼å¼ï¼Œé€‚ç”¨äºVLLMç­‰æ¡†æ¶\n",
    "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method=\"merged_16bit\")\n",
    "if False: model.push_to_hub_merged(\"ä½ çš„ç”¨æˆ·å/model\", tokenizer, save_method=\"merged_16bit\", token=\"ä½ çš„token\")\n",
    "\n",
    "# ä¿å­˜ä¸ºGGUFæ ¼å¼ï¼Œé€‚ç”¨äºllama.cppç­‰æ¡†æ¶\n",
    "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method=\"q4_k_m\")\n",
    "if False: model.push_to_hub_gguf(\"ä½ çš„ç”¨æˆ·å/model\", tokenizer, quantization_method=\"q4_k_m\", token=\"ä½ çš„token\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
